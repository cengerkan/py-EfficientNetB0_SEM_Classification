import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# ============================================
# 1. PARAMETRELER
# ============================================
IMG_SIZE = 224 
BATCH_SIZE = 32
EPOCHS = 50
LEARNING_RATE = 0.001

DATA_DIR = 'data100'  
CLASSES = ['Fibres', 'Nanowires', 'Particles', 'Powder']
NUM_CLASSES = len(CLASSES)

# ============================================
# 2. VERƒ∞ HAZIRLIƒûI
# ============================================
print("=" * 60)
print("VERƒ∞ HAZIRLANIYOR...")
print("=" * 60)

# Train-Validation split i√ßin veri jenerat√∂rleri
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    validation_split=0.2, 
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    fill_mode='nearest'
)

# Validation i√ßin sadece rescale
val_datagen = ImageDataGenerator(
    rescale=1. / 255,
    validation_split=0.2
)

# Training generator
train_generator = train_datagen.flow_from_directory(
    DATA_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

# Validation generator
val_generator = val_datagen.flow_from_directory(
    DATA_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)

print(f"\n‚úì Training √∂rnekleri: {train_generator.samples}")
print(f"‚úì Validation √∂rnekleri: {val_generator.samples}")
print(f"‚úì Sƒ±nƒ±flar: {train_generator.class_indices}")

# ============================================
# 3. MODEL OLU≈ûTURMA (EfficientNet B0)
# ============================================
print("\n" + "=" * 60)
print("MODEL OLU≈ûTURULUYOR...")
print("=" * 60)


def create_efficientnet_model():
    
    base_model = EfficientNetB0(
        include_top=False,
        weights='imagenet',
        input_shape=(IMG_SIZE, IMG_SIZE, 3)
    )

    # ƒ∞lk katmanlarƒ± dondur (transfer learning)
    base_model.trainable = False

    # Kendi classification head'imizi ekleyelim
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])

    return model, base_model


model, base_model = create_efficientnet_model()

# Model compile
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='categorical_crossentropy',
    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]
)

print("\n‚úì Model hazƒ±r!")
model.summary()

# ============================================
# 4. CALLBACKS
# ============================================
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    ),
    keras.callbacks.ModelCheckpoint(
        'best_efficientnet_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# ============================================
# 5. MODEL Eƒûƒ∞Tƒ∞Mƒ∞ - PHASE 1 (Frozen Base)
# ============================================
print("\n" + "=" * 60)
print("PHASE 1: Transfer Learning (Base model frozen)")
print("=" * 60)

history_phase1 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    callbacks=callbacks,
    verbose=1
)

# ============================================
# 6. FINE-TUNING - PHASE 2 (Unfreeze some layers)
# ============================================
print("\n" + "=" * 60)
print("PHASE 2: Fine-tuning (Unfreezing last layers)")
print("=" * 60)

# Base model'in son katmanlarƒ±nƒ± a√ß
base_model.trainable = True

# ƒ∞lk 100 katmanƒ± frozen tut
for layer in base_model.layers[:100]:
    layer.trainable = False

# Daha d√º≈ü√ºk learning rate ile re-compile
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE / 10),
    loss='categorical_crossentropy',
    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]
)

print(f"\n‚úì Trainable layers: {len([l for l in model.layers if l.trainable])}")

history_phase2 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=30,
    callbacks=callbacks,
    verbose=1,
    initial_epoch=history_phase1.epoch[-1]
)

# ============================================
# 7. MODEL DEƒûERLENDƒ∞RME
# ============================================
print("\n" + "=" * 60)
print("MODEL DEƒûERLENDƒ∞Rƒ∞Lƒ∞YOR...")
print("=" * 60)

# Final evaluation
val_loss, val_accuracy, val_top2_acc = model.evaluate(val_generator, verbose=1)
print(f"\n‚úì Validation Loss: {val_loss:.4f}")
print(f"‚úì Validation Accuracy: {val_accuracy:.4f} ({val_accuracy * 100:.2f}%)")
print(f"‚úì Top-2 Accuracy: {val_top2_acc:.4f} ({val_top2_acc * 100:.2f}%)")

# ============================================
# 8. TAHMƒ∞N VE CONFUSION MATRIX
# ============================================
print("\n" + "=" * 60)
print("TAHMƒ∞NLER YAPILIYOR...")
print("=" * 60)

# Validation seti √ºzerinde tahmin
val_generator.reset()
predictions = model.predict(val_generator, verbose=1)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = val_generator.classes
class_labels = list(val_generator.class_indices.keys())

# Classification Report
print("\nüìä CLASSIFICATION REPORT:")
print(classification_report(true_classes, predicted_classes, target_names=class_labels))

# Confusion Matrix
cm = confusion_matrix(true_classes, predicted_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix - EfficientNet B0', fontsize=16, fontweight='bold')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
print("\n‚úì Confusion matrix kaydedildi: confusion_matrix.png")

# ============================================
# 9. Eƒûƒ∞Tƒ∞M GRAFƒ∞KLERƒ∞
# ============================================
# T√ºm history'leri birle≈ütir
all_history = {
    'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],
    'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],
    'loss': history_phase1.history['loss'] + history_phase2.history['loss'],
    'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss']
}

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Accuracy
axes[0].plot(all_history['accuracy'], label='Train Accuracy', linewidth=2)
axes[0].plot(all_history['val_accuracy'], label='Val Accuracy', linewidth=2)
axes[0].axvline(x=len(history_phase1.history['accuracy']), color='red',
                linestyle='--', label='Fine-tuning Start')
axes[0].set_xlabel('Epoch', fontsize=12)
axes[0].set_ylabel('Accuracy', fontsize=12)
axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Loss
axes[1].plot(all_history['loss'], label='Train Loss', linewidth=2)
axes[1].plot(all_history['val_loss'], label='Val Loss', linewidth=2)
axes[1].axvline(x=len(history_phase1.history['loss']), color='red',
                linestyle='--', label='Fine-tuning Start')
axes[1].set_xlabel('Epoch', fontsize=12)
axes[1].set_ylabel('Loss', fontsize=12)
axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
print("‚úì Eƒüitim grafikleri kaydedildi: training_history.png")


# ============================================
# 10. TEK G√ñR√úNT√ú TAHMƒ∞N FONKSƒ∞YONU
# ============================================
def predict_single_image(image_path, model, class_labels):
    """Tek bir g√∂r√ºnt√º i√ßin tahmin yapar"""
    img = keras.preprocessing.image.load_img(
        image_path,
        target_size=(IMG_SIZE, IMG_SIZE)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0

    predictions = model.predict(img_array, verbose=0)
    predicted_class_idx = np.argmax(predictions[0])
    predicted_class = class_labels[predicted_class_idx]
    confidence = predictions[0][predicted_class_idx] * 100

    # T√ºm sƒ±nƒ±flar i√ßin olasƒ±lƒ±klar
    print(f"\nüîç Tahmin Sonu√ßlarƒ± - {image_path}")
    print("-" * 50)
    for idx, (label, prob) in enumerate(zip(class_labels, predictions[0])):
        marker = "‚úì" if idx == predicted_class_idx else " "
        print(f"{marker} {label:15s}: {prob * 100:6.2f}%")
    print("-" * 50)
    print(f"üéØ En Y√ºksek Tahmin: {predicted_class} ({confidence:.2f}%)")

    return predicted_class, confidence


# ============================================
# 11. MODEL KAYDETME
# ============================================
print("\n" + "=" * 60)
print("MODEL KAYDEDƒ∞Lƒ∞YOR...")
print("=" * 60)

model.save('efficientnet_b0_material_classifier.h5')
print("‚úì Model kaydedildi: efficientnet_b0_material_classifier.h5")

# Model bilgilerini kaydet
model_info = {
    'classes': class_labels,
    'img_size': IMG_SIZE,
    'val_accuracy': float(val_accuracy),
    'val_loss': float(val_loss)
}

import json

with open('model_info.json', 'w') as f:
    json.dump(model_info, f, indent=4)
print("‚úì Model bilgileri kaydedildi: model_info.json")

print("\n" + "=" * 60)
print("üéâ Eƒûƒ∞Tƒ∞M TAMAMLANDI!")
print("=" * 60)
print(f"\nüìÅ Olu≈üturulan Dosyalar:")
print(f"   ‚Ä¢ efficientnet_b0_material_classifier.h5")
print(f"   ‚Ä¢ best_efficientnet_model.h5")
print(f"   ‚Ä¢ confusion_matrix.png")
print(f"   ‚Ä¢ training_history.png")
print(f"   ‚Ä¢ model_info.json")

# ============================================
# 12. √ñRNEK KULLANIM (ƒ∞steƒüe baƒülƒ±)
# ============================================
print("\n" + "=" * 60)
print("√ñRNEK KULLANIM")
print("=" * 60)
print("\n# Tek g√∂r√ºnt√º i√ßin tahmin:")
print("predict_single_image('path/to/image.jpg', model, class_labels)")
print("\n# Kaydedilmi≈ü modeli y√ºklemek i√ßin:")
print("loaded_model = keras.models.load_model('efficientnet_b0_material_classifier.h5')")


#fine tunning 5 e kadar olmasƒ± yeterli g√∂r√ºld√º.
